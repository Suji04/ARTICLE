{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "X7ksV7kkEOfF"
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from glob import glob\n",
    "\n",
    "import torch\n",
    "from huggingface_hub import login\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "device = \"cuda\"\n",
    "login(token='HF_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LNp1vbXsEoc_"
   },
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\").to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y4N3YWvpFe1I"
   },
   "outputs": [],
   "source": [
    "D_voiced = pd.read_parquet(\"/content/drive/MyDrive/Sujan_Dutta/LLM Noise Audit/EMNLP 2024/Share/voiced_complete.parquet\")\n",
    "cat2bin = {'Extremely offensive': 1,\n",
    "            'Very offensive': 1,\n",
    "            'Moderately offensive': 1,\n",
    "            'Slightly offensive': 0,\n",
    "            'Not at all offensive': 0}\n",
    "\n",
    "def map_label(x):\n",
    "    if x==-1: return -1\n",
    "    if pd.isna(x): return -1\n",
    "    return cat2bin[x.strip()]\n",
    "\n",
    "D_voiced[\"PERSON_TOXIC\"] = D_voiced[\"PERSON_TOXIC_raw\"].apply(map_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6GElA4SAF7YR"
   },
   "outputs": [],
   "source": [
    "def prepare_annotator_group_data(data, pol_grp):\n",
    "    pol_comm = data[[\"comment_id\", \"comment_text\", \"annotator_id\", \"annotator_political\", \"PERSON_TOXIC\"]]\n",
    "    pol_comm = pol_comm[pol_comm[\"annotator_political\"]==pol_grp]\n",
    "    pol_comm = pol_comm.dropna()\n",
    "    pol_comm[\"PERSON_TOXIC\"] = pol_comm[\"PERSON_TOXIC\"].astype('int')\n",
    "    pol_comm = pol_comm[pol_comm[\"PERSON_TOXIC\"]!=-1]\n",
    "\n",
    "    annotators = list(pol_comm[\"annotator_id\"].unique())\n",
    "    re_n_shot_data = pd.DataFrame()\n",
    "    n_shot = 10\n",
    "    for ann in annotators:\n",
    "        _df = pol_comm[pol_comm[\"annotator_id\"]==ann]\n",
    "        train = _df.sample(n=n_shot)\n",
    "        test = _df[~_df.comment_id.isin(train.comment_id)]\n",
    "        train_test = pd.concat([train, test])\n",
    "        train_test[\"is_train\"] = [1]*n_shot+[0]*(len(train_test)-n_shot)\n",
    "        re_n_shot_data = pd.concat([re_n_shot_data, train_test])\n",
    "\n",
    "    re_n_shot_data.to_csv(f\"{pol_grp}_annotator_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "SqMJa_f3pUjv"
   },
   "outputs": [],
   "source": [
    "bin2label = {1: \"offensive\", 0: \"non-offensive\"}\n",
    "\n",
    "def predict_offense(df, text):\n",
    "    comments = df[\"comment_text\"]\n",
    "    labels = df[\"PERSON_TOXIC\"]\n",
    "    prompt = f\"\"\"\n",
    "You are an expert in guessing my response against a social media comment. Your task is to analyze and predict \\\n",
    "my response against the comment after <<<>>> into one of the following predefined categories:\n",
    "\n",
    "offensive\n",
    "non-offensive\n",
    "\n",
    "You will only respond with the predefined category. Do not provide explanations or notes.\n",
    "\n",
    "####\n",
    "Here are some examples:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    examples = \"\"\n",
    "    for i, (comment, label) in enumerate(zip(comments, labels)):\n",
    "        examples += f\"Comment: {comment}\\nResponse: {bin2label[label]}\\n\"\n",
    "\n",
    "    prompt += examples\n",
    "    prompt += f\"\"\"###\n",
    "\n",
    "<<<\n",
    "Comment: {text}\n",
    ">>>\n",
    "\"\"\"\n",
    "\n",
    "    messages = []\n",
    "    messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "    encodeds = tokenizer.apply_chat_template(messages, return_tensors=\"pt\").to(\"cuda\")\n",
    "    generated_ids = model.generate(encodeds, max_new_tokens=10, do_sample=False, eos_token_id=tokenizer.eos_token_id)\n",
    "    decoded = tokenizer.batch_decode(generated_ids)\n",
    "    return decoded[0].split(\"[/INST]\")[1].rstrip(\"</s>\").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FsrDiF7Ipm-Q"
   },
   "outputs": [],
   "source": [
    "def model_annotators(pol_grp):\n",
    "    n_shot_data = pd.read_csv(f\"{pol_grp}_annotator_data.csv\")\n",
    "    predictors = n_shot_data[\"annotator_id\"].unique()\n",
    "\n",
    "    for ann in tqdm(predictors[:20]):\n",
    "        ann_data = n_shot_data[n_shot_data[\"annotator_id\"]==ann]\n",
    "        train_data = ann_data[ann_data[\"is_train\"]==1].sample(frac=1)\n",
    "        test_data = ann_data[ann_data[\"is_train\"]==0]\n",
    "        test_data = test_data.sample(n=min(20,len(test_data)))\n",
    "\n",
    "        test_data[\"prediction\"] = test_data[\"comment_text\"].apply(lambda x: predict_offense(train_data, x))\n",
    "        test_data.to_csv(f\"{pol_grp}_pred_{ann}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aOQjZM2MqHcV"
   },
   "outputs": [],
   "source": [
    "def label2bin(text):\n",
    "    if text.lower().startswith(\"off\"): return 1\n",
    "    elif text.lower().startswith(\"non\"): return 0\n",
    "    else: return -1\n",
    "\n",
    "def compute_score(pol_grp):\n",
    "    all_df = pd.DataFrame()\n",
    "    for file in glob(f\"{pol_grp}_pred_*.csv\"):\n",
    "        df = pd.read_csv(file)\n",
    "        all_df = pd.concat([all_df, df])\n",
    "\n",
    "    all_df[\"prediction\"] = all_df[\"prediction\"].apply(label2bin)\n",
    "    result_arr = []\n",
    "    predictors = all_df[\"annotator_id\"].unique()\n",
    "    for ann in predictors:\n",
    "        ann_data = all_df[(all_df[\"annotator_id\"]==ann) & (all_df[\"prediction\"]!=-1)]\n",
    "        f1 = f1_score(ann_data[\"PERSON_TOXIC\"], ann_data[\"prediction\"], average=\"macro\")\n",
    "        result_arr.append([ann, f1])\n",
    "\n",
    "    result_df = pd.DataFrame(result_arr, columns=[\"annotator_id\", \"f1\"])\n",
    "    result_df.to_csv(f\"{pol_grp}_annotator_score.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bmetKxv9okOJ"
   },
   "outputs": [],
   "source": [
    "group = \"Democrat\" ## \"Republican\", \"Independent\"\n",
    "prepare_annotator_group_data(D_voiced, group)\n",
    "model_annotators(group)\n",
    "compute_score(group)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
